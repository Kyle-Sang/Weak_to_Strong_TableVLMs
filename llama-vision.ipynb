{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.50.0.dev0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.2)\n",
      "Collecting unsloth\n",
      "  Downloading unsloth-2025.3.9-py3-none-any.whl.metadata (59 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.13)\n",
      "Collecting unsloth_zoo>=2025.3.8 (from unsloth)\n",
      "  Downloading unsloth_zoo-2025.3.8-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (2.6.0)\n",
      "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
      "  Downloading xformers-0.0.29.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting bitsandbytes (from unsloth)\n",
      "  Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.2.0)\n",
      "Collecting tyro (from unsloth)\n",
      "  Downloading tyro-0.9.17-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.2.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth) (7.0.0)\n",
      "Collecting wheel>=0.42.0 (from unsloth)\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.4.0)\n",
      "Collecting trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9 (from unsloth)\n",
      "  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting peft!=0.11.0,>=0.7.1 (from unsloth)\n",
      "  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting protobuf<4.0.0 (from unsloth)\n",
      "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n",
      "Collecting hf_transfer (from unsloth)\n",
      "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting diffusers (from unsloth)\n",
      "  Downloading diffusers-0.32.2-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.21.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.1.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (13.9.4)\n",
      "Collecting cut_cross_entropy (from unsloth_zoo>=2025.3.8->unsloth)\n",
      "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2025.3.8->unsloth) (11.1.0)\n",
      "Collecting importlib-metadata (from diffusers->unsloth)\n",
      "  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\n",
      "Collecting docstring-parser>=0.15 (from tyro->unsloth)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting shtab>=1.5.6 (from tyro->unsloth)\n",
      "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typeguard>=4.0.0 (from tyro->unsloth)\n",
      "  Downloading typeguard-4.4.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (2.19.1)\n",
      "Collecting zipp>=3.20 (from importlib-metadata->diffusers->unsloth)\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (0.1.2)\n",
      "Downloading unsloth-2025.3.9-py3-none-any.whl (191 kB)\n",
      "Downloading peft-0.14.0-py3-none-any.whl (374 kB)\n",
      "Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.15.2-py3-none-any.whl (318 kB)\n",
      "Downloading unsloth_zoo-2025.3.8-py3-none-any.whl (112 kB)\n",
      "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading xformers-0.0.29.post3-cp310-cp310-manylinux_2_28_x86_64.whl (43.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading diffusers-0.32.2-py3-none-any.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tyro-0.9.17-py3-none-any.whl (123 kB)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "Downloading typeguard-4.4.2-py3-none-any.whl (35 kB)\n",
      "Downloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
      "Downloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
      "Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: zipp, wheel, typeguard, shtab, protobuf, hf_transfer, docstring-parser, importlib-metadata, tyro, diffusers, xformers, cut_cross_entropy, bitsandbytes, peft, trl, unsloth_zoo, unsloth\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.37.1\n",
      "    Uninstalling wheel-0.37.1:\n",
      "      Successfully uninstalled wheel-0.37.1\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.29.3\n",
      "    Uninstalling protobuf-5.29.3:\n",
      "      Successfully uninstalled protobuf-5.29.3\n",
      "Successfully installed bitsandbytes-0.45.3 cut_cross_entropy-25.1.1 diffusers-0.32.2 docstring-parser-0.16 hf_transfer-0.1.9 importlib-metadata-8.6.1 peft-0.14.0 protobuf-3.20.3 shtab-1.7.1 trl-0.15.2 typeguard-4.4.2 tyro-0.9.17 unsloth-2025.3.9 unsloth_zoo-2025.3.8 wheel-0.45.1 xformers-0.0.29.post3 zipp-3.21.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "!pip install transformers datasets unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.3.9: Fast Mllama patching. Transformers: 4.50.0.dev0.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4090. Num GPUs = 1. Max memory: 23.64 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.30s/it]\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastVisionModel\n",
    "\n",
    "model, tokenizer = FastVisionModel.from_pretrained(\n",
    "    \"unsloth/Llama-3.2-11B-Vision-Instruct\",\n",
    "    load_in_4bit = True, # Use 4bit to reduce memory use. False for 16bit LoRA.\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for long context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Making `model.base_model.model.language_model.model` require gradients\n"
     ]
    }
   ],
   "source": [
    "model = FastVisionModel.get_peft_model(\n",
    "    model,\n",
    "    finetune_vision_layers     = False, # False if not finetuning vision layers\n",
    "    finetune_language_layers   = True, # False if not finetuning language layers\n",
    "    finetune_attention_modules = True, # False if not finetuning attention layers\n",
    "    finetune_mlp_modules       = True, # False if not finetuning MLP layers\n",
    "\n",
    "    r = 16,           # The larger, the higher the accuracy, but might overfit\n",
    "    lora_alpha = 16,  # Recommended alpha == r at least\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    "    # target_modules = \"all-linear\", # Optional now! Can specify a list if needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_vlm_dataset(data, images=False):\n",
    "\n",
    "    vlm_dataset = []\n",
    "    for sample in tqdm(data):\n",
    "        if images:\n",
    "            image_path = sample['tables']['images']['table_column_color']\n",
    "            table = Image.open(image_path)\n",
    "            instruction = (\"You are given an image of a table below.\"\n",
    "            \" Assert whether the statement is true or false based on the table.\"\n",
    "            \" If the statement is true, answer \\'1\\'. If the statement is false, answer \\'0\\'.\")\n",
    "        else:\n",
    "            table = sample[\"tables\"][\"bracket\"] # Markdown version of table\n",
    "            instruction = (\"You are given a table in markdown form below.\"\n",
    "            \" Assert whether the statement is true or false based on the table.\"\n",
    "            \" If the statement is true, answer \\'1\\'. If the statement is false, answer \\'0\\'.\")\n",
    "\n",
    "        question = f\"### STATEMENT: {sample['question']}\"  # Assuming 'question' key holds the question\n",
    "        \n",
    "        # Convert image filepath to PIL Image\n",
    "        \n",
    "\n",
    "        # Structure as VLM format with instruction and question\n",
    "        vlm_sample = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": instruction}, # Main instruction\n",
    "                        {\"type\": \"image\", \"image\": table} if images else {\"type\": \"text\", \"text\": table},  # Add image if available\n",
    "                        {\"type\": \"text\", \"text\": question} # The question about the image\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": sample['answer']}  # Leave answer blank for the model to generate\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        vlm_dataset.append(vlm_sample)\n",
    "\n",
    "    return vlm_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the JSON file\n",
    "with open('./tabFact_data/tabFact.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "train_data = data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92283/92283 [00:10<00:00, 8873.33it/s] \n"
     ]
    }
   ],
   "source": [
    "vlm_dataset = create_vlm_dataset(train_data, images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def save_vlm_dataset_pickle(vlm_dataset, filepath):\n",
    "    with open(filepath, 'wb') as f:  # 'wb' for writing in binary mode\n",
    "        pickle.dump(vlm_dataset, f)\n",
    "\n",
    "# Usage:\n",
    "# save_vlm_dataset_pickle(vlm_dataset, \"tabFact_column_color_image.pkl\") # KERNEL CRASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=1000x300>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vlm_dataset[0]['messages'][0]['content'][1]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': \"You are given an image of a table below. Assert whether the statement is true or false based on the table. If the statement is true, answer '1'. If the statement is false, answer '0'.\"},\n",
       "    {'type': 'image',\n",
       "     'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1000x300>},\n",
       "    {'type': 'text',\n",
       "     'text': '### STATEMENT: haroldo be mention as a brazil scorer for 2 different game'}]},\n",
       "  {'role': 'assistant', 'content': [{'type': 'text', 'text': 1}]}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vlm_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The table shows that haroldo was mentioned as a brazilian scorer for 2 different games.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "FastVisionModel.for_inference(model) # Enable for inference!\n",
    "\n",
    "image = vlm_dataset[0]['messages'][0]['content'][1]['image']\n",
    "messages = vlm_dataset[0]['messages']\n",
    "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt = True)\n",
    "inputs = tokenizer(\n",
    "    image,\n",
    "    input_text,\n",
    "    add_special_tokens = False,\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128,\n",
    "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import is_bf16_supported\n",
    "from unsloth.trainer import UnslothVisionDataCollator\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "\n",
    "FastVisionModel.for_training(model) # Enable for training!\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = UnslothVisionDataCollator(model, tokenizer), # Must use!\n",
    "    train_dataset = vlm_dataset,\n",
    "    args = SFTConfig(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        # max_steps = 30,\n",
    "        num_train_epochs = 2, # Set this instead of max_steps for full training runs\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bf16_supported(),\n",
    "        bf16 = is_bf16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "\n",
    "        save_strategy=\"epoch\",  # Save at the end of each epoch\n",
    "        save_steps=-1,  # Automatically save at epoch end\n",
    "        save_total_limit=-1,  # No limit on the total number of saved checkpoints\n",
    "        output_dir = \"llama-3.2-11B-Vision-Instruct-finetuned_TabFact_ColumnColor\",  # Directory to save the model\n",
    "        report_to = \"none\",     # For Weights and Biases\n",
    "\n",
    "        # You MUST put the below items for vision finetuning:\n",
    "        remove_unused_columns = False,\n",
    "        dataset_text_field = \"\",\n",
    "        dataset_kwargs = {\"skip_prepare_dataset\": True},\n",
    "        dataset_num_proc = 4,\n",
    "        max_seq_length = 2048,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 92,283 | Num Epochs = 2 | Total steps = 23,070\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 52,428,800/6,197,126,691 (0.85% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='864' max='23070' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  864/23070 59:31 < 25:33:33, 0.24 it/s, Epoch 0.07/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.925400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.187600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.996900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.440300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.970400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.521800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.179100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.156000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.716700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.873300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.771200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.750500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.883900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.664700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.746000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.599000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.739600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.518400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.524900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.707300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.587300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.530900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.532200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.774900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.431300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.497800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.684700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.444800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.526000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.407500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.535600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.584200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.452000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.508000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.507400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.561300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.548400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.476700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.437200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.553200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.424400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.501100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.520300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.472600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.431100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.484700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.493400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.482500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.572000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.447500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.438700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.551700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.572600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.432400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.637800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.552300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.523700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.483600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.445600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.510900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.540900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.475800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.521500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.622300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.481300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.544400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.370400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.446400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.395300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.547500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.496100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.517400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.420800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.488900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.500800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.361500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.499800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.573800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.496900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.457000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.439700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.497000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.438700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.480300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.520300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.583000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.500100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.569800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.448500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.461500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.547300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.390700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.452000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.478000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.387800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.456900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.436900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.457000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.415300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.464800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.472200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.472900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.419800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.551000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.520300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>0.506400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.483300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>0.528900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.478900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>0.482200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.493000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.454400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.485200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>0.514000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.385000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>0.402300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.556100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>0.495200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>0.473700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>0.412600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.439700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.437900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>0.427600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>0.468300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.356200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>0.528700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.392400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>0.430100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>0.516400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>0.459600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>0.561300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.448300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>0.551200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>0.494700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>0.581500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>0.466200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.466200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>0.437600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>0.384200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>0.450800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>0.621700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>0.506600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>0.431400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>0.526900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>0.471800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>0.424400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.421300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>0.532600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>0.492600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>0.530400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>0.440700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>0.605400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>0.450400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>0.435400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>0.538600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>0.364500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.502100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>0.377600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>0.318700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>0.446100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>0.368600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.442200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>0.586500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>0.491000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>0.464800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>0.611000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.599300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>0.431300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>0.454700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>0.402900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>0.461700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.445200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>0.506000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>0.447100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>0.343000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>0.489500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.653900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>0.357000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>0.517500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>0.533800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>0.446600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>0.449300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>0.451500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>0.369600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>0.447700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>0.480800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.441200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>0.456500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.425100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>0.495900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>0.433900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0.469000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>0.436400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>0.458100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>0.379200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>0.415600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.494500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201</td>\n",
       "      <td>0.445600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202</td>\n",
       "      <td>0.502000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203</td>\n",
       "      <td>0.575800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>0.550100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>0.461500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>0.428500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207</td>\n",
       "      <td>0.399500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208</td>\n",
       "      <td>0.512900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>209</td>\n",
       "      <td>0.458500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.434500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211</td>\n",
       "      <td>0.355200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212</td>\n",
       "      <td>0.460800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213</td>\n",
       "      <td>0.572900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214</td>\n",
       "      <td>0.440300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>0.428100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>0.467900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217</td>\n",
       "      <td>0.430800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218</td>\n",
       "      <td>0.464900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>219</td>\n",
       "      <td>0.568000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.356400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>221</td>\n",
       "      <td>0.414500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>222</td>\n",
       "      <td>0.462600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223</td>\n",
       "      <td>0.561100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.507600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.526900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>0.379800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227</td>\n",
       "      <td>0.422800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228</td>\n",
       "      <td>0.515900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>229</td>\n",
       "      <td>0.408000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.448800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>231</td>\n",
       "      <td>0.453600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232</td>\n",
       "      <td>0.441100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233</td>\n",
       "      <td>0.400800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>234</td>\n",
       "      <td>0.643200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>0.506800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236</td>\n",
       "      <td>0.319700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237</td>\n",
       "      <td>0.394300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>0.446900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239</td>\n",
       "      <td>0.450200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.436800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>241</td>\n",
       "      <td>0.420400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242</td>\n",
       "      <td>0.464900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>243</td>\n",
       "      <td>0.464000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244</td>\n",
       "      <td>0.501200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>0.414500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>0.462300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247</td>\n",
       "      <td>0.438500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>0.427800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>0.509500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.518600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>251</td>\n",
       "      <td>0.435100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>0.464800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>0.486100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>254</td>\n",
       "      <td>0.435500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>0.678600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.342800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257</td>\n",
       "      <td>0.473200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258</td>\n",
       "      <td>0.445900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>259</td>\n",
       "      <td>0.435500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.377300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>261</td>\n",
       "      <td>0.397800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>262</td>\n",
       "      <td>0.379700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>263</td>\n",
       "      <td>0.478800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>0.470300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265</td>\n",
       "      <td>0.519500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>266</td>\n",
       "      <td>0.368100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>267</td>\n",
       "      <td>0.445900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>268</td>\n",
       "      <td>0.380700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>269</td>\n",
       "      <td>0.420100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.472700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>271</td>\n",
       "      <td>0.459600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>272</td>\n",
       "      <td>0.451300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>273</td>\n",
       "      <td>0.362700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>274</td>\n",
       "      <td>0.407800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.539000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>276</td>\n",
       "      <td>0.444800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>277</td>\n",
       "      <td>0.463100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>278</td>\n",
       "      <td>0.474100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>279</td>\n",
       "      <td>0.465200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.455700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>281</td>\n",
       "      <td>0.416500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>282</td>\n",
       "      <td>0.523900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>283</td>\n",
       "      <td>0.458400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284</td>\n",
       "      <td>0.486800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>0.602000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286</td>\n",
       "      <td>0.579400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>287</td>\n",
       "      <td>0.392700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.459000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>289</td>\n",
       "      <td>0.453600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.529700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>291</td>\n",
       "      <td>0.435800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292</td>\n",
       "      <td>0.424200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>293</td>\n",
       "      <td>0.382600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>0.351200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>0.415900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>0.547500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>0.500500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>0.575700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>0.338700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.566900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>301</td>\n",
       "      <td>0.491400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>302</td>\n",
       "      <td>0.389000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>303</td>\n",
       "      <td>0.328100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>304</td>\n",
       "      <td>0.441900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>305</td>\n",
       "      <td>0.515400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>306</td>\n",
       "      <td>0.388100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>307</td>\n",
       "      <td>0.410200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>308</td>\n",
       "      <td>0.444800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>309</td>\n",
       "      <td>0.414200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.403100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>311</td>\n",
       "      <td>0.408800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>312</td>\n",
       "      <td>0.448100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>313</td>\n",
       "      <td>0.431500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>314</td>\n",
       "      <td>0.535700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315</td>\n",
       "      <td>0.410700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>316</td>\n",
       "      <td>0.356600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>317</td>\n",
       "      <td>0.329400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>318</td>\n",
       "      <td>0.493500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>319</td>\n",
       "      <td>0.438700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.352900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>321</td>\n",
       "      <td>0.400800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>322</td>\n",
       "      <td>0.398800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>323</td>\n",
       "      <td>0.353100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>324</td>\n",
       "      <td>0.403000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.401300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>326</td>\n",
       "      <td>0.403800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>327</td>\n",
       "      <td>0.425600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>328</td>\n",
       "      <td>0.406400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>329</td>\n",
       "      <td>0.492600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.383800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>331</td>\n",
       "      <td>0.478900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>332</td>\n",
       "      <td>0.591700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>333</td>\n",
       "      <td>0.409300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>334</td>\n",
       "      <td>0.487700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>335</td>\n",
       "      <td>0.471200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>336</td>\n",
       "      <td>0.424200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>337</td>\n",
       "      <td>0.445600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>338</td>\n",
       "      <td>0.585600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339</td>\n",
       "      <td>0.438100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.485700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>341</td>\n",
       "      <td>0.482100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>342</td>\n",
       "      <td>0.484800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>343</td>\n",
       "      <td>0.516800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>344</td>\n",
       "      <td>0.312300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>345</td>\n",
       "      <td>0.506500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>346</td>\n",
       "      <td>0.472400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>347</td>\n",
       "      <td>0.462400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>348</td>\n",
       "      <td>0.395300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>349</td>\n",
       "      <td>0.424100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.507300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>351</td>\n",
       "      <td>0.420600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.528400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>353</td>\n",
       "      <td>0.465500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>354</td>\n",
       "      <td>0.456300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>355</td>\n",
       "      <td>0.445200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>356</td>\n",
       "      <td>0.401600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>357</td>\n",
       "      <td>0.520200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>358</td>\n",
       "      <td>0.431300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>359</td>\n",
       "      <td>0.457500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.469400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>361</td>\n",
       "      <td>0.458700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>362</td>\n",
       "      <td>0.528500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>363</td>\n",
       "      <td>0.446600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>364</td>\n",
       "      <td>0.370900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>365</td>\n",
       "      <td>0.459800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>366</td>\n",
       "      <td>0.501800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>367</td>\n",
       "      <td>0.417100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>368</td>\n",
       "      <td>0.403500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>369</td>\n",
       "      <td>0.436000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.439400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>371</td>\n",
       "      <td>0.450500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>372</td>\n",
       "      <td>0.486700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>373</td>\n",
       "      <td>0.463300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>374</td>\n",
       "      <td>0.412200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.472200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>376</td>\n",
       "      <td>0.479100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>377</td>\n",
       "      <td>0.443700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>378</td>\n",
       "      <td>0.445400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>379</td>\n",
       "      <td>0.420900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.463500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>381</td>\n",
       "      <td>0.596900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>382</td>\n",
       "      <td>0.393600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>383</td>\n",
       "      <td>0.533100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.441600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>385</td>\n",
       "      <td>0.506300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>386</td>\n",
       "      <td>0.416600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>387</td>\n",
       "      <td>0.406300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>388</td>\n",
       "      <td>0.326300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>389</td>\n",
       "      <td>0.464600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>391</td>\n",
       "      <td>0.412600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>392</td>\n",
       "      <td>0.605600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>393</td>\n",
       "      <td>0.371200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>394</td>\n",
       "      <td>0.511100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>0.469300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>0.499500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>0.418400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>0.679900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>0.393900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.424900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>401</td>\n",
       "      <td>0.474000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>402</td>\n",
       "      <td>0.601800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>403</td>\n",
       "      <td>0.427900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404</td>\n",
       "      <td>0.457600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>405</td>\n",
       "      <td>0.439000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>406</td>\n",
       "      <td>0.447600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>407</td>\n",
       "      <td>0.612100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408</td>\n",
       "      <td>0.449900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>409</td>\n",
       "      <td>0.514100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.415400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411</td>\n",
       "      <td>0.424300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>412</td>\n",
       "      <td>0.555500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>413</td>\n",
       "      <td>0.469700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>414</td>\n",
       "      <td>0.443500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>415</td>\n",
       "      <td>0.485300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>0.410900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>417</td>\n",
       "      <td>0.567100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>418</td>\n",
       "      <td>0.521600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>419</td>\n",
       "      <td>0.429400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.403700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>421</td>\n",
       "      <td>0.365700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>422</td>\n",
       "      <td>0.543500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>423</td>\n",
       "      <td>0.389100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>424</td>\n",
       "      <td>0.562100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.355300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>426</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>427</td>\n",
       "      <td>0.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>428</td>\n",
       "      <td>0.384000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>429</td>\n",
       "      <td>0.447100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.452700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>431</td>\n",
       "      <td>0.459900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>432</td>\n",
       "      <td>0.456000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>433</td>\n",
       "      <td>0.454700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>434</td>\n",
       "      <td>0.419500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>435</td>\n",
       "      <td>0.475600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>436</td>\n",
       "      <td>0.395500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>437</td>\n",
       "      <td>0.484000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>438</td>\n",
       "      <td>0.407900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>439</td>\n",
       "      <td>0.499200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.356300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>441</td>\n",
       "      <td>0.405700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>442</td>\n",
       "      <td>0.372200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>443</td>\n",
       "      <td>0.414700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>444</td>\n",
       "      <td>0.476300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>445</td>\n",
       "      <td>0.374600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>446</td>\n",
       "      <td>0.402600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>447</td>\n",
       "      <td>0.470400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>0.570200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>449</td>\n",
       "      <td>0.356800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.402100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>451</td>\n",
       "      <td>0.461800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>452</td>\n",
       "      <td>0.452000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>453</td>\n",
       "      <td>0.462300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>454</td>\n",
       "      <td>0.396800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>455</td>\n",
       "      <td>0.436800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>456</td>\n",
       "      <td>0.442000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>457</td>\n",
       "      <td>0.409900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>458</td>\n",
       "      <td>0.496900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>459</td>\n",
       "      <td>0.596500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.454700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>461</td>\n",
       "      <td>0.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>462</td>\n",
       "      <td>0.409100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>463</td>\n",
       "      <td>0.440300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>464</td>\n",
       "      <td>0.508400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>465</td>\n",
       "      <td>0.494600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>466</td>\n",
       "      <td>0.467800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>467</td>\n",
       "      <td>0.378400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>468</td>\n",
       "      <td>0.429200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>469</td>\n",
       "      <td>0.548000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.397400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>471</td>\n",
       "      <td>0.405500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472</td>\n",
       "      <td>0.443900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>473</td>\n",
       "      <td>0.366900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>474</td>\n",
       "      <td>0.633700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.338600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>476</td>\n",
       "      <td>0.577400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>477</td>\n",
       "      <td>0.428100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>478</td>\n",
       "      <td>0.429800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>479</td>\n",
       "      <td>0.440100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.459700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>481</td>\n",
       "      <td>0.414200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>482</td>\n",
       "      <td>0.437300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>483</td>\n",
       "      <td>0.446500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>484</td>\n",
       "      <td>0.514800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>485</td>\n",
       "      <td>0.341800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>486</td>\n",
       "      <td>0.382600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>487</td>\n",
       "      <td>0.496400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>488</td>\n",
       "      <td>0.404200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>489</td>\n",
       "      <td>0.432700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.441500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>491</td>\n",
       "      <td>0.465000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>492</td>\n",
       "      <td>0.477900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>493</td>\n",
       "      <td>0.541400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>494</td>\n",
       "      <td>0.433100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>0.487300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>0.392600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>497</td>\n",
       "      <td>0.449300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498</td>\n",
       "      <td>0.478000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499</td>\n",
       "      <td>0.419900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.406500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>501</td>\n",
       "      <td>0.371100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>502</td>\n",
       "      <td>0.503100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>503</td>\n",
       "      <td>0.384200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>504</td>\n",
       "      <td>0.539700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>505</td>\n",
       "      <td>0.399100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>506</td>\n",
       "      <td>0.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>507</td>\n",
       "      <td>0.375800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>508</td>\n",
       "      <td>0.413000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>509</td>\n",
       "      <td>0.474000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.357800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>511</td>\n",
       "      <td>0.447600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>0.428300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>513</td>\n",
       "      <td>0.487000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>514</td>\n",
       "      <td>0.436100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>515</td>\n",
       "      <td>0.404400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>516</td>\n",
       "      <td>0.498200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>517</td>\n",
       "      <td>0.480500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>518</td>\n",
       "      <td>0.356700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>519</td>\n",
       "      <td>0.476700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.514900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>521</td>\n",
       "      <td>0.555300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>522</td>\n",
       "      <td>0.537800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>523</td>\n",
       "      <td>0.442500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>524</td>\n",
       "      <td>0.425400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>526</td>\n",
       "      <td>0.427700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>527</td>\n",
       "      <td>0.393100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>528</td>\n",
       "      <td>0.384500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>529</td>\n",
       "      <td>0.381800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.489600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>531</td>\n",
       "      <td>0.402700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>532</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>533</td>\n",
       "      <td>0.432000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>534</td>\n",
       "      <td>0.493200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>535</td>\n",
       "      <td>0.556500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>536</td>\n",
       "      <td>0.438300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>537</td>\n",
       "      <td>0.398600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>538</td>\n",
       "      <td>0.562100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>539</td>\n",
       "      <td>0.438500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.433700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>541</td>\n",
       "      <td>0.366400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>542</td>\n",
       "      <td>0.450400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>543</td>\n",
       "      <td>0.473800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>544</td>\n",
       "      <td>0.451000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>545</td>\n",
       "      <td>0.435400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>546</td>\n",
       "      <td>0.414200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>547</td>\n",
       "      <td>0.440900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>548</td>\n",
       "      <td>0.518000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>549</td>\n",
       "      <td>0.390200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.435200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>551</td>\n",
       "      <td>0.586500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>552</td>\n",
       "      <td>0.424500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>553</td>\n",
       "      <td>0.399900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>554</td>\n",
       "      <td>0.396000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>555</td>\n",
       "      <td>0.385900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>556</td>\n",
       "      <td>0.525400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>557</td>\n",
       "      <td>0.585600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>558</td>\n",
       "      <td>0.505200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>559</td>\n",
       "      <td>0.472400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.438000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>561</td>\n",
       "      <td>0.455700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>562</td>\n",
       "      <td>0.450900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>563</td>\n",
       "      <td>0.566500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>564</td>\n",
       "      <td>0.495900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>565</td>\n",
       "      <td>0.466400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>566</td>\n",
       "      <td>0.421900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567</td>\n",
       "      <td>0.362500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568</td>\n",
       "      <td>0.362900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>569</td>\n",
       "      <td>0.467200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.461000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>571</td>\n",
       "      <td>0.430300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>572</td>\n",
       "      <td>0.485600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>573</td>\n",
       "      <td>0.513600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>574</td>\n",
       "      <td>0.379900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.493500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>576</td>\n",
       "      <td>0.595600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>577</td>\n",
       "      <td>0.470700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>578</td>\n",
       "      <td>0.489700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>579</td>\n",
       "      <td>0.486600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.390800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>581</td>\n",
       "      <td>0.476100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>582</td>\n",
       "      <td>0.387800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>583</td>\n",
       "      <td>0.471500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>584</td>\n",
       "      <td>0.411800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>585</td>\n",
       "      <td>0.449900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>586</td>\n",
       "      <td>0.365600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>587</td>\n",
       "      <td>0.418500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>588</td>\n",
       "      <td>0.543000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>589</td>\n",
       "      <td>0.472900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.384800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>591</td>\n",
       "      <td>0.453000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>592</td>\n",
       "      <td>0.376300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>593</td>\n",
       "      <td>0.547300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>594</td>\n",
       "      <td>0.413000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>595</td>\n",
       "      <td>0.543100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>596</td>\n",
       "      <td>0.305700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>597</td>\n",
       "      <td>0.344700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>598</td>\n",
       "      <td>0.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>599</td>\n",
       "      <td>0.362700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>601</td>\n",
       "      <td>0.375400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>602</td>\n",
       "      <td>0.481600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>603</td>\n",
       "      <td>0.518400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>604</td>\n",
       "      <td>0.414700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>605</td>\n",
       "      <td>0.449800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>606</td>\n",
       "      <td>0.388200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>607</td>\n",
       "      <td>0.455900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>608</td>\n",
       "      <td>0.405800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>609</td>\n",
       "      <td>0.496300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.480100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>611</td>\n",
       "      <td>0.435700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>612</td>\n",
       "      <td>0.503700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>613</td>\n",
       "      <td>0.417200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>614</td>\n",
       "      <td>0.442800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>615</td>\n",
       "      <td>0.370200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>616</td>\n",
       "      <td>0.537800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>617</td>\n",
       "      <td>0.378600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>618</td>\n",
       "      <td>0.498500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>619</td>\n",
       "      <td>0.328400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.467800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>621</td>\n",
       "      <td>0.381100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>622</td>\n",
       "      <td>0.356700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>623</td>\n",
       "      <td>0.468400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>624</td>\n",
       "      <td>0.379900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.447600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>626</td>\n",
       "      <td>0.412600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>627</td>\n",
       "      <td>0.400500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>628</td>\n",
       "      <td>0.426500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>629</td>\n",
       "      <td>0.410300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>631</td>\n",
       "      <td>0.495200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>632</td>\n",
       "      <td>0.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>633</td>\n",
       "      <td>0.407600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>634</td>\n",
       "      <td>0.528900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>635</td>\n",
       "      <td>0.493600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>636</td>\n",
       "      <td>0.398000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>637</td>\n",
       "      <td>0.464000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>638</td>\n",
       "      <td>0.441800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>639</td>\n",
       "      <td>0.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.482600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>641</td>\n",
       "      <td>0.421000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>642</td>\n",
       "      <td>0.534100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>643</td>\n",
       "      <td>0.463500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>644</td>\n",
       "      <td>0.508600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>645</td>\n",
       "      <td>0.330400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>646</td>\n",
       "      <td>0.403200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>647</td>\n",
       "      <td>0.435100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>648</td>\n",
       "      <td>0.448800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>649</td>\n",
       "      <td>0.400900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.461700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>651</td>\n",
       "      <td>0.424000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>652</td>\n",
       "      <td>0.471300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>653</td>\n",
       "      <td>0.439400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>654</td>\n",
       "      <td>0.413300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>655</td>\n",
       "      <td>0.415100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>656</td>\n",
       "      <td>0.539500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>657</td>\n",
       "      <td>0.381900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>658</td>\n",
       "      <td>0.531800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>659</td>\n",
       "      <td>0.402500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.506700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>661</td>\n",
       "      <td>0.510600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>662</td>\n",
       "      <td>0.487600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>663</td>\n",
       "      <td>0.389800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>664</td>\n",
       "      <td>0.498500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>665</td>\n",
       "      <td>0.462000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>666</td>\n",
       "      <td>0.440100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>667</td>\n",
       "      <td>0.386700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>668</td>\n",
       "      <td>0.587500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>669</td>\n",
       "      <td>0.463100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.464200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>671</td>\n",
       "      <td>0.393100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>672</td>\n",
       "      <td>0.475800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>673</td>\n",
       "      <td>0.525000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>674</td>\n",
       "      <td>0.386400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.443200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>676</td>\n",
       "      <td>0.380700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>677</td>\n",
       "      <td>0.455200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>678</td>\n",
       "      <td>0.390300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>679</td>\n",
       "      <td>0.453300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.419600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>681</td>\n",
       "      <td>0.573200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>682</td>\n",
       "      <td>0.411100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>683</td>\n",
       "      <td>0.380100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>684</td>\n",
       "      <td>0.424500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>685</td>\n",
       "      <td>0.464500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>686</td>\n",
       "      <td>0.438100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>687</td>\n",
       "      <td>0.437100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>688</td>\n",
       "      <td>0.513900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>689</td>\n",
       "      <td>0.370700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.482400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>691</td>\n",
       "      <td>0.370100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>692</td>\n",
       "      <td>0.408100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>693</td>\n",
       "      <td>0.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>694</td>\n",
       "      <td>0.540500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>695</td>\n",
       "      <td>0.617700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>696</td>\n",
       "      <td>0.479400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>697</td>\n",
       "      <td>0.339800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>698</td>\n",
       "      <td>0.504400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>699</td>\n",
       "      <td>0.419700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.518700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>701</td>\n",
       "      <td>0.322500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>702</td>\n",
       "      <td>0.408600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>703</td>\n",
       "      <td>0.501100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>704</td>\n",
       "      <td>0.383200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>705</td>\n",
       "      <td>0.389000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>706</td>\n",
       "      <td>0.505300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>707</td>\n",
       "      <td>0.460500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>708</td>\n",
       "      <td>0.436400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>709</td>\n",
       "      <td>0.529500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.411300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>711</td>\n",
       "      <td>0.473800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>712</td>\n",
       "      <td>0.476200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>713</td>\n",
       "      <td>0.388400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>714</td>\n",
       "      <td>0.527300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>715</td>\n",
       "      <td>0.320700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>716</td>\n",
       "      <td>0.510400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>717</td>\n",
       "      <td>0.446600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>718</td>\n",
       "      <td>0.385000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>719</td>\n",
       "      <td>0.596000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.418700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>721</td>\n",
       "      <td>0.527500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>722</td>\n",
       "      <td>0.516500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>723</td>\n",
       "      <td>0.399100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>724</td>\n",
       "      <td>0.398300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>0.481500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>726</td>\n",
       "      <td>0.493200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>727</td>\n",
       "      <td>0.439600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>728</td>\n",
       "      <td>0.462400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>729</td>\n",
       "      <td>0.426900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.519300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>731</td>\n",
       "      <td>0.340200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>732</td>\n",
       "      <td>0.503100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>733</td>\n",
       "      <td>0.389800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>734</td>\n",
       "      <td>0.410500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>735</td>\n",
       "      <td>0.448300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>736</td>\n",
       "      <td>0.391700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>737</td>\n",
       "      <td>0.421100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>738</td>\n",
       "      <td>0.383000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>739</td>\n",
       "      <td>0.418600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.472600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>741</td>\n",
       "      <td>0.404600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>742</td>\n",
       "      <td>0.653100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>743</td>\n",
       "      <td>0.460600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>744</td>\n",
       "      <td>0.474200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>745</td>\n",
       "      <td>0.408000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>746</td>\n",
       "      <td>0.377900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>747</td>\n",
       "      <td>0.536100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>748</td>\n",
       "      <td>0.454400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>749</td>\n",
       "      <td>0.349300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.616500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>751</td>\n",
       "      <td>0.446600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>752</td>\n",
       "      <td>0.442300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>753</td>\n",
       "      <td>0.357400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>754</td>\n",
       "      <td>0.500500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>755</td>\n",
       "      <td>0.338700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>756</td>\n",
       "      <td>0.457000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>757</td>\n",
       "      <td>0.503800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>758</td>\n",
       "      <td>0.376600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>759</td>\n",
       "      <td>0.454000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.461100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>761</td>\n",
       "      <td>0.366400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>762</td>\n",
       "      <td>0.380300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>763</td>\n",
       "      <td>0.534700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>764</td>\n",
       "      <td>0.486000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>765</td>\n",
       "      <td>0.448200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>766</td>\n",
       "      <td>0.389000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>767</td>\n",
       "      <td>0.396000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>768</td>\n",
       "      <td>0.328700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>769</td>\n",
       "      <td>0.431100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.411700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>771</td>\n",
       "      <td>0.462200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>772</td>\n",
       "      <td>0.558400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>773</td>\n",
       "      <td>0.409100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>774</td>\n",
       "      <td>0.534400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>0.398600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>776</td>\n",
       "      <td>0.430200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>777</td>\n",
       "      <td>0.436400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>778</td>\n",
       "      <td>0.389900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>779</td>\n",
       "      <td>0.456400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.396200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>781</td>\n",
       "      <td>0.399800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>782</td>\n",
       "      <td>0.344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>783</td>\n",
       "      <td>0.484600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>784</td>\n",
       "      <td>0.362700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>785</td>\n",
       "      <td>0.449300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>786</td>\n",
       "      <td>0.502400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>787</td>\n",
       "      <td>0.504000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>788</td>\n",
       "      <td>0.473800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>789</td>\n",
       "      <td>0.352700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.385700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>791</td>\n",
       "      <td>0.433400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>792</td>\n",
       "      <td>0.445600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>793</td>\n",
       "      <td>0.543100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>794</td>\n",
       "      <td>0.312400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>795</td>\n",
       "      <td>0.424700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>796</td>\n",
       "      <td>0.416500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>797</td>\n",
       "      <td>0.422800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>798</td>\n",
       "      <td>0.413900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>799</td>\n",
       "      <td>0.467800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.393800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>801</td>\n",
       "      <td>0.461700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>802</td>\n",
       "      <td>0.423000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>803</td>\n",
       "      <td>0.399600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>804</td>\n",
       "      <td>0.457900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>805</td>\n",
       "      <td>0.435700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>806</td>\n",
       "      <td>0.439700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>807</td>\n",
       "      <td>0.461400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>808</td>\n",
       "      <td>0.389800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>809</td>\n",
       "      <td>0.467200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.328800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>811</td>\n",
       "      <td>0.568400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>812</td>\n",
       "      <td>0.428400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>813</td>\n",
       "      <td>0.411000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>814</td>\n",
       "      <td>0.353000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>815</td>\n",
       "      <td>0.555300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>816</td>\n",
       "      <td>0.427800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>817</td>\n",
       "      <td>0.503700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>818</td>\n",
       "      <td>0.602000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>819</td>\n",
       "      <td>0.404000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.395900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>821</td>\n",
       "      <td>0.395500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>822</td>\n",
       "      <td>0.376400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>823</td>\n",
       "      <td>0.460400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>824</td>\n",
       "      <td>0.438900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>0.469300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>826</td>\n",
       "      <td>0.353500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>827</td>\n",
       "      <td>0.476300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>828</td>\n",
       "      <td>0.467300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>829</td>\n",
       "      <td>0.368600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.582600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>831</td>\n",
       "      <td>0.358800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>832</td>\n",
       "      <td>0.418000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>833</td>\n",
       "      <td>0.378900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>834</td>\n",
       "      <td>0.473100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>835</td>\n",
       "      <td>0.438100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>836</td>\n",
       "      <td>0.334400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>837</td>\n",
       "      <td>0.403600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>838</td>\n",
       "      <td>0.432800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>839</td>\n",
       "      <td>0.404100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.446600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>841</td>\n",
       "      <td>0.457700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>842</td>\n",
       "      <td>0.455600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>843</td>\n",
       "      <td>0.419200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>844</td>\n",
       "      <td>0.377500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>845</td>\n",
       "      <td>0.366900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>846</td>\n",
       "      <td>0.521900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>847</td>\n",
       "      <td>0.439400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>848</td>\n",
       "      <td>0.388800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>849</td>\n",
       "      <td>0.340100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.444200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>851</td>\n",
       "      <td>0.408100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>852</td>\n",
       "      <td>0.571500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>853</td>\n",
       "      <td>0.408400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>854</td>\n",
       "      <td>0.470600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>855</td>\n",
       "      <td>0.401200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>856</td>\n",
       "      <td>0.375100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>857</td>\n",
       "      <td>0.380600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>858</td>\n",
       "      <td>0.469100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>859</td>\n",
       "      <td>0.395500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.396200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>861</td>\n",
       "      <td>0.537600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>862</td>\n",
       "      <td>0.421600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.2.15: Fast Llama patching. Transformers: 4.50.0.dev0.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4090. Max memory: 23.64 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "checkpoint_path = \"outputs/checkpoint-2500\"\n",
    "model = FastLanguageModel.from_pretrained(checkpoint_path)\n",
    "tokenizer = model[1]\n",
    "model = model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.2.15: Fast Llama patching. Transformers: 4.50.0.dev0.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4090. Max memory: 23.64 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 3072, padding_idx=128004)\n",
       "        (layers): ModuleList(\n",
       "          (0): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "          )\n",
       "          (1): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=8192, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "          )\n",
       "          (2-27): 26 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint_path = \"outputs/checkpoint-2500\"\n",
    "\n",
    "# Load model and tokenizer, ensuring they are on GPU\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(checkpoint_path)\n",
    "model = FastLanguageModel.for_inference(model)\n",
    "model.to(\"cuda\")  # Move model to GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Given this table: [['Year', 'Division', 'League', 'Regular Season', 'Playoffs', 'Open Cup', 'Avg. Attendance'], ['2001', '2', 'USL A-League', '4th, Western', 'Quarterfinals', 'Did not qualify', '7,169'], ['2002', '2', 'USL A-League', '2nd, Pacific', '1st Round', 'Did not qualify', '6,260'], ['2003', '2', 'USL A-League', '3rd, Pacific', 'Did not qualify', 'Did not qualify', '5,871'], ['2004', '2', 'USL A-League', '1st, Western', 'Quarterfinals', '4th Round', '5,628'], ['2005', '2', 'USL First Division', '5th', 'Quarterfinals', '4th Round', '6,028'], ['2006', '2', 'USL First Division', '11th', 'Did not qualify', '3rd Round', '5,575'], ['2007', '2', 'USL First Division', '2nd', 'Semifinals', '2nd Round', '6,851'], ['2008', '2', 'USL First Division', '11th', 'Did not qualify', '1st Round', '8,567'], ['2009', '2', 'USL First Division', '1st', 'Semifinals', '3rd Round', '9,734'], ['2010', '2', 'USSF D-2 Pro League', '3rd, USL (3rd)', 'Quarterfinals', '3rd Round', '10,727']]. Answer the following. question: What was the last year where this team was a part of the USL A-League?, answer: 2004\n",
      " question:\n",
      "Output: Given this table: [['Year', 'Division', 'League', 'Regular Season', 'Playoffs', 'Open Cup', 'Avg. Attendance'], ['2001', '2', 'USL A-League', '4th, Western', 'Quarterfinals', 'Did not qualify', '7,169'], ['2002', '2', 'USL A-League', '2nd, Pacific', '1st Round', 'Did not qualify', '6,260'], ['2003', '2', 'USL A-League', '3rd, Pacific', 'Did not qualify', 'Did not qualify', '5,871'], ['2004', '2', 'USL A-League', '1st, Western', 'Quarterfinals', '4th Round', '5,628'], ['2005', '2', 'USL First Division', '5th', 'Quarterfinals', '4th Round', '6,028'], ['2006', '2', 'USL First Division', '11th', 'Did not qualify', '3rd Round', '5,575'], ['2007', '2', 'USL First Division', '2nd', 'Semifinals', '2nd Round', '6,851'], ['2008', '2', 'USL First Division', '11th', 'Did not qualify', '1st Round', '8,567'], ['2009', '2', 'USL First Division', '1st', 'Semifinals', '3rd Round', '9,734'], ['2010', '2', 'USSF D-2 Pro League', '3rd, USL (3rd)', 'Quarterfinals', '3rd Round', '10,727']]. Answer the following. question: What was the last year where this team was a part of the USL A-League?, answer: 2004\n",
      " question: what was the name of the first team this team was a part of before becoming an independent team?\n",
      "\\\\n'2001', '2', 'USL A-League', '4th, Western', 'Quarterfinals', 'Did not qualify', '7,169'], ['2002', '2', 'USL A-League', '2nd, Pacific', '1st Round', 'Did not qualify', '6,260'], ['2003', '2', 'USL A-League', '3rd, Pacific', 'Did not qualify', 'Did not qualify', '5,871'], ['2004', '2', 'USL A-League', '1st, Western', 'Quarterfinals', '4th Round', '5,628'], ['2005', '2', 'USL First Division', '5th', 'Quarterfinals', '4th Round', '6,028'], ['2006', '2', 'USL First Division', '11th', 'Did not qualify', '3rd Round', '5,575'], ['2007', '2', 'USL First Division', '2nd', 'Semifinals', '2nd Round', '6,851'], ['2008', '2', 'USL First Division', '11th', 'Did not qualify', '1st Round', '8,567'], ['2009', '2', 'USL First Division', '1st', 'Semifinals', '3rd Round', '9,734'], ['2010', '2', 'USSF D-2 Pro League', '3rd, USL (3rd)', 'Quarterfinals', '3rd Round', '10,727']] ['2011', '2', 'USSF D-2 Pro League', '–', '–', '2nd Round', '10,778']] ['2012', '2', 'USSF D-2 Pro League', '3rd, USL (4th)', 'Quarterfinals', '3rd Round', '11,526']] ['2013', '2', 'USSF D-2 Pro League', '2nd, USL (6th)', 'Quarterfinals', '2nd Round', '12,154']] ['2014', '2', 'USSF D-2 Pro League', '–', '–', 'Did not qualify', '–']] ['Total', 'Total', 'Total', '18', 'Division 2', '14', ''], ['Total', 'Total', 'Total', '18', 'League Average', '7,562', '']]\n"
     ]
    }
   ],
   "source": [
    "# Sample input text\n",
    "table = \"[['Year', 'Division', 'League', 'Regular Season', 'Playoffs', 'Open Cup', 'Avg. Attendance'], ['2001', '2', 'USL A-League', '4th, Western', 'Quarterfinals', 'Did not qualify', '7,169'], ['2002', '2', 'USL A-League', '2nd, Pacific', '1st Round', 'Did not qualify', '6,260'], ['2003', '2', 'USL A-League', '3rd, Pacific', 'Did not qualify', 'Did not qualify', '5,871'], ['2004', '2', 'USL A-League', '1st, Western', 'Quarterfinals', '4th Round', '5,628'], ['2005', '2', 'USL First Division', '5th', 'Quarterfinals', '4th Round', '6,028'], ['2006', '2', 'USL First Division', '11th', 'Did not qualify', '3rd Round', '5,575'], ['2007', '2', 'USL First Division', '2nd', 'Semifinals', '2nd Round', '6,851'], ['2008', '2', 'USL First Division', '11th', 'Did not qualify', '1st Round', '8,567'], ['2009', '2', 'USL First Division', '1st', 'Semifinals', '3rd Round', '9,734'], ['2010', '2', 'USSF D-2 Pro League', '3rd, USL (3rd)', 'Quarterfinals', '3rd Round', '10,727']]\"\n",
    "question = \"What was the last year where this team was a part of the USL A-League?\"\n",
    "answer = \"2004\"\n",
    "input_text = f\"Given this table: {table}. Answer the following. question: {question}, answer: {answer}\\n question:\"\n",
    "\n",
    "# Encode the input text and move it to GPU\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# Generate output using the model\n",
    "output_ids = model.generate(input_ids, max_length=2048)\n",
    "\n",
    "# Decode the output to text\n",
    "output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"Input: {input_text}\")\n",
    "print(f\"Output: {output_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Please read the following table and answer the questions. question: what was the name of the first team this team was a part of before becoming an independent team?, [['Year', 'Division', 'League', 'Regular Season', 'Playoffs', 'Open Cup', 'Avg. Attendance'], ['2001', '2', 'USL A-League', '4th, Western', 'Quarterfinals', 'Did not qualify', '7,169'], ['2002', '2', 'USL A-League', '2nd, Pacific', '1st Round', 'Did not qualify', '6,260'], ['2003', '2', 'USL A-League', '3rd, Pacific', 'Did not qualify', 'Did not qualify', '5,871'], ['2004', '2', 'USL A-League', '1st, Western', 'Quarterfinals', '4th Round', '5,628'], ['2005', '2', 'USL First Division', '5th', 'Quarterfinals', '4th Round', '6,028'], ['2006', '2', 'USL First Division', '11th', 'Did not qualify', '3rd Round', '5,575'], ['2007', '2', 'USL First Division', '2nd', 'Semifinals', '2nd Round', '6,851'], ['2008', '2', 'USL First Division', '11th', 'Did not qualify', '1st Round', '8,567'], ['2009', '2', 'USL First Division', '1st', 'Semifinals', '3rd Round', '9,734'], ['2010', '2', 'USSF D-2 Pro League', '3rd, USL (3rd)', 'Quarterfinals', '3rd Round', '10,727']] answer:\n",
      "Output: Please read the following table and answer the questions. question: what was the name of the first team this team was a part of before becoming an independent team?, [['Year', 'Division', 'League', 'Regular Season', 'Playoffs', 'Open Cup', 'Avg. Attendance'], ['2001', '2', 'USL A-League', '4th, Western', 'Quarterfinals', 'Did not qualify', '7,169'], ['2002', '2', 'USL A-League', '2nd, Pacific', '1st Round', 'Did not qualify', '6,260'], ['2003', '2', 'USL A-League', '3rd, Pacific', 'Did not qualify', 'Did not qualify', '5,871'], ['2004', '2', 'USL A-League', '1st, Western', 'Quarterfinals', '4th Round', '5,628'], ['2005', '2', 'USL First Division', '5th', 'Quarterfinals', '4th Round', '6,028'], ['2006', '2', 'USL First Division', '11th', 'Did not qualify', '3rd Round', '5,575'], ['2007', '2', 'USL First Division', '2nd', 'Semifinals', '2nd Round', '6,851'], ['2008', '2', 'USL First Division', '11th', 'Did not qualify', '1st Round', '8,567'], ['2009', '2', 'USL First Division', '1st', 'Semifinals', '3rd Round', '9,734'], ['2010', '2', 'USSF D-2 Pro League', '3rd, USL (3rd)', 'Quarterfinals', '3rd Round', '10,727']] answer: first division\n"
     ]
    }
   ],
   "source": [
    "# Sample input text\n",
    "table = \"[['Year', 'Division', 'League', 'Regular Season', 'Playoffs', 'Open Cup', 'Avg. Attendance'], ['2001', '2', 'USL A-League', '4th, Western', 'Quarterfinals', 'Did not qualify', '7,169'], ['2002', '2', 'USL A-League', '2nd, Pacific', '1st Round', 'Did not qualify', '6,260'], ['2003', '2', 'USL A-League', '3rd, Pacific', 'Did not qualify', 'Did not qualify', '5,871'], ['2004', '2', 'USL A-League', '1st, Western', 'Quarterfinals', '4th Round', '5,628'], ['2005', '2', 'USL First Division', '5th', 'Quarterfinals', '4th Round', '6,028'], ['2006', '2', 'USL First Division', '11th', 'Did not qualify', '3rd Round', '5,575'], ['2007', '2', 'USL First Division', '2nd', 'Semifinals', '2nd Round', '6,851'], ['2008', '2', 'USL First Division', '11th', 'Did not qualify', '1st Round', '8,567'], ['2009', '2', 'USL First Division', '1st', 'Semifinals', '3rd Round', '9,734'], ['2010', '2', 'USSF D-2 Pro League', '3rd, USL (3rd)', 'Quarterfinals', '3rd Round', '10,727']]\"\n",
    "question = \"what was the name of the first team this team was a part of before becoming an independent team?\"\n",
    "answer = \"2004\"\n",
    "input_text = f\"Please read the following table and answer the questions. question: {question}, {table} answer:\"\n",
    "\n",
    "# Encode the input text and move it to GPU\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# Generate output using the model\n",
    "output_ids = model.generate(input_ids, max_length=2048)\n",
    "\n",
    "# Decode the output to text\n",
    "output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"Input: {input_text}\")\n",
    "print(f\"Output: {output_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
